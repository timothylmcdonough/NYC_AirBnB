{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python 3\n",
    "\n",
    "# This script pull in salary data, builds and tests several predictive models\n",
    "# and then makes salary predictions on test data using the best model\n",
    "\n",
    "__author__ = 'Tim McDonough'\n",
    "__email__ = 'timothylmcdonough@gmail.com'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_file(file):\n",
    "    '''loads csv to pd dataframe'''\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "def consolidate_data(df1, df2, key=None, left_index=False, right_index=False):\n",
    "    '''perform inner join to return only records that are present in both dataframes'''\n",
    "    return pd.merge(left=df1, right=df2, how='inner', on=key, left_index=left_index, right_index=right_index)\n",
    "\n",
    "def clean data(raw_df):\n",
    "    '''remove rows that contain salary <= 0 or dupliate job IDS'''\n",
    "    clean_df = raw_df.drop_duplicates(subset='jobID')\n",
    "    clean_df = clean_df[clean_df.salary]\n",
    "    return clean_df\n",
    "\n",
    "def one_hot_encode_feature_df(df, cat_vars=None, num_vars=None):\n",
    "    '''performs one-hot encoding on all categorical variables and combines result with continuous variables'''\n",
    "    cat_df = pd.get_dummies(df[cat_vars])\n",
    "    num_df = df[num_vars].apply(pd.to_numeric)\n",
    "    return pd.concat([cat_df, num_df], axis=1)#ignore_index=False)\n",
    "\n",
    "def get_target_df(df, target):\n",
    "    '''returns target dataframe'''\n",
    "    return df[target]\n",
    "\n",
    "def train_model(model, feature_df, target_df, num procs, mean_mse, cv_std):\n",
    "    neg_mse = cross_val_score(model, feature_df, target_df, cv=2, n_jobs=num_procs, scoring='neg_mean_squared_error')\n",
    "    mean_mse[model] = -1.0*np.mean(neg_mse)\n",
    "    cv_std[model] = np.std(neg_mse)\n",
    "    \n",
    "def print_summary(model, mean_mse, cv_std):\n",
    "    print('\\nModel:\\n', model)\n",
    "    print('Average MSE:\\n', mean_mse[model])\n",
    "    print('Standard deviation during CV:\\n', cv_std[model])\n",
    "    \n",
    "def save_results(model, mean_mse, predictions, feature_importances):\n",
    "        '''saves model, model summary, feature importances, and predictions'''''\n",
    "        with open('model.txt', 'w') as file:\n",
    "                file.write(str(model))\n",
    "        feature_importances.to_csv('feature_importances.csv')\n",
    "        np.savetxt('predictions.csv', predictions, delimiter=',')\n",
    "        \n",
    "if __name__ = '__main__':\n",
    "    #define inputs\n",
    "    train_freature_file = 'data/train_features.csv'\n",
    "    train_target_file = 'data/train_salaries.csv'\n",
    "    test_feature_file = 'data/test_feature.csv'\n",
    "    \n",
    "    #define variables\n",
    "    categorical_vars =['companyId', 'jobType', 'degree,' ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
