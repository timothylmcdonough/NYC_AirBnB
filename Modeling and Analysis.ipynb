{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author = 'Timothy McDonough'\n",
    "### Email = 'timothylmcdonough@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4b. Modeling and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries to perform model analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define \"FeatureGenerator\" and \"ModelContainer\" classes to create functions needed to perform the model analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator:\n",
    "    def __init__(self, data):\n",
    "        '''initializes class and creates groupby object for data'''\n",
    "        self.data = data\n",
    "        #able to generate features for new companies, but less accurate\n",
    "        #self.cat_cols = ['jobType', 'degree', 'major', 'industry']\n",
    "        self.cat_cols = data.cat_cols\n",
    "        self.groups = data.train_df.groupby(self.cat_cols)\n",
    "        \n",
    "    def add_group_stats(self):\n",
    "        '''adds group statistics to data stored in data object'''\n",
    "        #get group stats\n",
    "        group_stats_df = self._get_group_stats()\n",
    "        group_stats_df.reset_index(inplace=True)\n",
    "  \n",
    "        #merge derived columns to original df\n",
    "        self.data.train_df = self._merge_new_cols(self.data.train_df, group_stats_df, self.cat_cols, fillna=True)\n",
    "        self.data.test_df = self._merge_new_cols(self.data.test_df, group_stats_df, self.cat_cols, fillna=True)      \n",
    "        \n",
    "        #update column lists\n",
    "        group_stats_cols = ['group_mean', 'group_max', 'group_min', 'group_std', 'group_median']\n",
    "        self._extend_col_lists(self.data, cat_cols=group_stats_cols)  \n",
    "        \n",
    "    def _get_group_stats(self):\n",
    "        '''calculates group statistics'''\n",
    "        target_col = self.data.target_col\n",
    "        group_stats_df = pd.DataFrame({'group_mean': self.groups[target_col].mean()})\n",
    "        group_stats_df['group_max'] = self.groups[target_col].max()\n",
    "        group_stats_df['group_min'] = self.groups[target_col].min()\n",
    "        group_stats_df['group_std'] = self.groups[target_col].std()\n",
    "        group_stats_df['group_median'] = self.groups[target_col].median()\n",
    "        return group_stats_df\n",
    "        \n",
    "    def _merge_new_cols(self, df, new_cols_df, keys, fillna=False):\n",
    "        '''merges engineered features with original df'''\n",
    "        df = pd.merge(df, new_cols_df, on=keys, how='left')\n",
    "        if fillna:\n",
    "            df.fillna(0, inplace=True)\n",
    "        return df\n",
    "        \n",
    "    def _extend_col_lists(self, data, cat_cols=[], num_cols=[]):\n",
    "        '''addes engineered feature cols to data col lists'''\n",
    "        data.num_cols.extend(num_cols)\n",
    "        data.cat_cols.extend(cat_cols)\n",
    "        data.feature_cols.extend(num_cols + cat_cols)\n",
    "\n",
    "\n",
    "class ModelContainer:\n",
    "    def __init__(self, models=[]):#, default_num_iters=10, verbose_lvl=0):\n",
    "        '''initializes model list and dicts'''\n",
    "        self.models = models\n",
    "        self.best_model = None\n",
    "        self.predictions = None\n",
    "        self.mean_mse = {}\n",
    "        #self.default_num_iters = default_num_iters\n",
    "        #self.verbose_lvl = verbose_lvl\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "\n",
    "    def cross_validate(self, data, k=3, num_procs=1):\n",
    "        '''cross validate models using given data'''\n",
    "        feature_df = data.train_df[data.feature_cols]\n",
    "        target_df = data.train_df[data.target_col]\n",
    "        for model in self.models:\n",
    "            neg_mse = cross_val_score(model, feature_df, target_df, cv=k, n_jobs=num_procs, scoring='neg_mean_squared_error')\n",
    "            self.mean_mse[model] = -1.0*np.mean(neg_mse)\n",
    "    \n",
    "    def select_best_model(self):\n",
    "        '''select model with lowest mse'''\n",
    "        self.best_model = min(self.mean_mse, key=self.mean_mse.get)\n",
    "        \n",
    "    def best_model_fit(self, features, targets):\n",
    "        '''fits best model'''\n",
    "        self.best_model.fit(features, targets)\n",
    "    \n",
    "    def best_model_predict(self, features):\n",
    "        '''scores features using best model'''\n",
    "        self.predictions = self.best_model.predict(features)\n",
    "        \n",
    "    def save_results(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_feature_importance(model, cols):\n",
    "        '''retrieves and sorts feature importances'''\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            feature_importances = pd.DataFrame({'feature':cols, 'importance':importances})\n",
    "            feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "            #set index to 'feature'\n",
    "            feature_importances.set_index('feature', inplace=True, drop=True)\n",
    "            return feature_importances\n",
    "        else:\n",
    "            #some models don't have feature_importances_\n",
    "            return \"Feature importances do not exist for given model\"\n",
    "\n",
    "    def print_summary(self):\n",
    "        '''prints summary of models, best model, and feature importance'''\n",
    "        print('\\nModel Summaries:\\n')\n",
    "        for model in models.mean_mse:\n",
    "            print('\\n', model, '- MSE:', models.mean_mse[model])\n",
    "        print('\\nBest Model:\\n', models.best_model)\n",
    "        print('\\nMSE of Best Model\\n', models.mean_mse[models.best_model])\n",
    "        print('\\nFeature Importances\\n', models.get_feature_importance(models.best_model, data.feature_cols))\n",
    "\n",
    "        feature_importances = self.get_feature_importance(models.best_model, data.feature_cols)\n",
    "        feature_importances.plot.bar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summaries:\n",
      "\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) - MSE: 5168.409186943802\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) - MSE: 5248.7010193285605\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 6783.161711760639\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) - MSE: 5168.409186943802\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) - MSE: 5206.696185322099\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 6765.832192917419\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) - MSE: 5168.409186943802\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) - MSE: 5273.8671123433505\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 6841.376803861615\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) - MSE: 5168.409186943802\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) - MSE: 5215.76376255548\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 6847.138537736551\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) - MSE: 5168.409186943802\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) - MSE: 5160.83050302503\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 6822.4416532350115\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) - MSE: 5168.409186943802\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) - MSE: 5224.990187375502\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 6797.081019099438\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) - MSE: 5168.409186943802\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) - MSE: 5177.912473819757\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 6834.453453616356\n",
      "\n",
      "Best Model:\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)\n",
      "\n",
      "MSE of Best Model\n",
      " 5160.83050302503\n",
      "\n",
      "Feature Importances\n",
      "                      importance\n",
      "feature                        \n",
      "group_mean             0.490540\n",
      "host_id                0.251007\n",
      "group_std              0.142535\n",
      "group_max              0.044932\n",
      "group_median           0.037637\n",
      "group_min              0.020508\n",
      "neighbourhood          0.012841\n",
      "neighbourhood_group    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model analysis and selection\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #move working directory to correct location\n",
    "    os.chdir('/Users/timothylmcdonough/DSDJ/NYC_AirBnB')\n",
    "    \n",
    "    #define number of processors to use for parallel runs\n",
    "    num_procs = 4\n",
    "\n",
    "    #set verbose level for models\n",
    "    verbose_lvl = 0\n",
    "\n",
    "    #define input files\n",
    "    train_feature_file = 'Data/train_features.csv'\n",
    "    train_target_file = 'Data/train_prices.csv'\n",
    "    test_file = 'Data/test_features.csv'\n",
    "\n",
    "    #define variables\n",
    "    #cat_cols = ['name', 'host_id', 'host_name', 'neighbourhood_group', 'neighbourhood', 'room_type', 'last_review']\n",
    "    cat_cols = ['neighbourhood_group', 'neighbourhood']\n",
    "\n",
    "    #num_cols = ['latitude', 'longitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\n",
    "    num_cols = ['host_id']\n",
    "    target_col = 'price'\n",
    "    id_col = 'name'\n",
    "\n",
    "    #turn feature engineering on\n",
    "    engineer_features = True\n",
    "    \n",
    "    #Create Data object\n",
    "    data = Data(train_feature_file, train_target_file, test_file, cat_cols, num_cols, target_col, id_col)\n",
    "    \n",
    "    #Engineer features\n",
    "    if engineer_features:\n",
    "        feature_generator = FeatureGenerator(data)\n",
    "        feature_generator.add_group_stats()\n",
    "\n",
    "    #Create model container and add models to it\n",
    "    models = ModelContainer()\n",
    "\n",
    "    #create models -- hyperparameter tuning already done by hand for each model\n",
    "    models.add_model(LinearRegression())\n",
    "    models.add_model(RandomForestRegressor(n_estimators=60, n_jobs=num_procs, max_depth=15, min_samples_split=80,                                        max_features=8, verbose=verbose_lvl))\n",
    "    models.add_model(GradientBoostingRegressor(n_estimators=40, max_depth=7, loss='ls', verbose=verbose_lvl))\n",
    "\n",
    "    #Cross validate models, then select, fit, and score test data with best model\n",
    "    models.cross_validate(data, k=2, num_procs=num_procs)\n",
    "    models.select_best_model()\n",
    "    models.best_model_fit(data.train_df[data.feature_cols], data.train_df[data.target_col])\n",
    "    models.best_model_predict(data.test_df[data.feature_cols])\n",
    "\n",
    "    #Summarize results\n",
    "    models.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
